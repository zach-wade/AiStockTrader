# Layer 1 Backfill Configuration
# This file defines optimal data collection settings for Layer 1 qualified symbols
# Layer 1 symbols are the most liquid ~2,000 stocks that pass liquidity filters

layer1_backfill:
  # Description of this backfill strategy
  description: "Comprehensive historical data collection for Layer 1 qualified symbols"
  
  # Symbol selection
  symbol_source: "layer1"  # Uses database query for layer1_qualified = true
  
  # Global settings
  force_refresh: false     # Set to true to re-download existing data
  continue_on_error: true  # Continue if individual symbols fail
  max_retries: 3          # Retry failed downloads
  
  # Data collection stages in priority order
  stages:
    # Stage 1: Long-term market data (highest priority)
    long_term:
      description: "Daily and hourly bars for technical analysis and model training"
      lookback_days: 1825  # 5 years
      priority: 1
      enabled: true
      data_type: "market_data"
      rationale: |
        - Captures multiple market cycles (bull/bear)
        - Sufficient for moving averages up to 200-day
        - Enables seasonal pattern detection
        - Optimal for ML model training
      
    # Stage 2: Intraday data for scanners
    scanner_intraday:
      description: "Minute bars for intraday pattern recognition"
      lookback_days: 365   # 1 year
      priority: 2
      enabled: true
      data_type: "market_data"
      rationale: |
        - Recent microstructure most relevant
        - Storage-intensive (limit to 1 year)
        - Critical for day trading strategies
        - Enables volume profile analysis
      
    # Stage 3: News sentiment data
    news_data:
      description: "News articles for sentiment analysis and event studies"
      lookback_days: 730   # 2 years
      priority: 3
      enabled: true
      data_type: "news"
      rationale: |
        - News impact decays quickly
        - 2 years captures recent sentiment shifts
        - Sufficient for earnings reaction studies
        - Manageable storage footprint
      
    # Stage 4: Corporate actions (extended history)
    corporate_actions:
      description: "Splits, dividends, earnings dates for fundamental analysis"
      lookback_days: 3650  # 10 years
      priority: 4
      enabled: true
      data_type: "corporate_actions"
      rationale: |
        - Low frequency, low storage cost
        - Critical for accurate price adjustments
        - Needed for dividend strategy analysis
        - Historical earnings patterns valuable
      
    # Stage 5: Fundamentals data (financial statements)
    fundamentals:
      description: "Financial statements and key metrics from Yahoo Finance"
      lookback_days: 1825  # 5 years
      priority: 5
      enabled: true
      data_type: "fundamentals"
      rationale: |
        - Essential for fundamental analysis
        - Quarterly and annual financial statements
        - Key financial ratios and metrics
        - Relatively low frequency updates
      
    # Stage 6: Social sentiment (optional)
    social_sentiment:
      description: "Reddit, Twitter sentiment if available"
      lookback_days: 180   # 6 months
      priority: 6
      enabled: false  # Enable if social data sources configured
      data_type: "social_sentiment"
      optional: true
      rationale: |
        - Very recent data most relevant
        - High noise, rapid decay
        - Storage intensive
        - Optional based on strategy needs
      
    # Stage 7: Options data (optional)
    options_data:
      description: "Options chain for volatility analysis"
      lookback_days: 365   # 1 year
      priority: 7
      enabled: false  # Enable if options trading active
      data_type: "options"
      optional: true
      rationale: |
        - Needed for options strategies
        - Implied volatility analysis
        - Greeks calculation
        - Storage intensive

  # Execution settings
  execution:
    # Run stages sequentially to avoid API overload
    parallel_stages: false
    
    # Batch processing
    batch_size: 100  # Process symbols in batches
    
    # Progress tracking
    checkpoint_interval: 50  # Save progress every N symbols
    progress_file: "data/backfill_progress/layer1_backfill.json"
    
    # Resource limits
    max_memory_gb: 8.0
    max_api_calls_per_minute: 300  # Respect API rate limits
    
  # Storage estimates (for 2,000 symbols)
  storage_estimates:
    long_term: "500 MB - 1 GB"
    scanner_intraday: "50 - 100 GB"
    news_data: "5 - 10 GB"
    corporate_actions: "1 GB"
    social_sentiment: "2 - 5 GB (if enabled)"
    options_data: "20 - 40 GB (if enabled)"
    total_estimated: "~60 - 120 GB (core stages)"
    
  # Scheduling recommendations
  schedule:
    initial_backfill: "Run once after Layer 1 qualification"
    daily_update: "Update with new data daily at 6 AM ET"
    weekly_refresh: "Re-qualify Layer 1 universe weekly"
    monthly_cleanup: "Archive/compress old minute data monthly"